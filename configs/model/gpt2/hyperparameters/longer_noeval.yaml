trainer_kwargs: # passed to TrainingArguments
  # Batch size
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 1

  # Core hyperparameters
  learning_rate: 5.e-5
  num_train_epochs: 25

  # Evaluation
  evaluation_strategy: "no"

  # Logging
  logging_strategy: epoch

  # Early stopping
  load_best_model_at_end: false
  metric_for_best_model: eval_loss
  save_strategy: epoch
  save_total_limit: 1

  # Outputs
  output_dir: output
